---
title: "INFLUENZA HOSPITALIZATIONS RESULTS"
author: "Victor Felix"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  pdf_document: default
---

This document summarizes the results of the 12 models with log-back transformations that were developed: AUTO ARIMA, AUTO ADJACENT, AUTO EPIWEEK, ES27 TEMPERATURE, ES27 ARIMA, ES27 ADJACENT, ES27 EPIWEEK, ES64 TEMPERATURE, ES64 ARIMA, ES64 ADJACENT, ES64 EPIWEEK, ES64 TEMPERATURE. It has a series of histograms and maps that compare the results of these models based on their WIS. You can read more about the specific covariates and ensemble techniques of these models in their own Rmarkdown documents. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Loading libraries.

```{r}
library("tidyr")
library("MMWRweek")
library("data.table")
library("caret")
library("purrr")
library("dplyr")
library("tseries")
library("gtools")
library("forecast")
library("scoringutils")
library("covidHubUtils")
library("parallel")
library("future")#https://cran.r-project.org/web/packages/future/vignettes/future-4-issues.html
library("listenv")
library("epitools")
library("ggplot2")
library("sf")
library("forcats")
library("ggplot2")
library("sf")
library("dplyr")
library("scales")  # For `breaks_extended`
library("ggplot2")
library("broom")
library("fields")

```

Loading the results of each model and the shapefiles of the maps.

```{r}
load("ES_ARIMA/ARIMA_MODELS_influenza_hospitalization.Rdata")
load("ES_ADJACENT/ADJACENT_MODELS_influenza_hospitalization.Rdata")
load("ES_EPIWEEK/EPIWEEK_MODELS_influenza_hospitalization.Rdata")
load("ES_TEMPERATURE/TEMPERATURE_MODELS_influenza_hospitalization.Rdata")

states <- read_sf("shapefiles/cb_2018_us_state_500k.shp")

states <- states %>%
  rename(STATE = NAME)

```

The results come as lists of dataframes with all states (e.g. AUTO_ARIMA_WEEK1_list) or as a single dataframe which combines all states (e.g. AUTO_ARIMA_WEEK1). Each model was run for forecasting 1-4 weeks ahead (e.g. AUTO_ARIMA_WEEK1, AUTO_ARIMA_WEEK2, AUTO_ARIMA_WEEK3, AUTO_ARIMA_WEEK4).

For easier visualization create some variables and plot some of the results for a specific model:

```{r}
# Here we extract the results of the ES27_ARIMA model which was utilized to forecast 1 WEEK ahead for the state of Alabama.

my_wis<- AUTO_ARIMA_WEEK1_list$Alabama[['WIS']] # get the actual cases
my_cases<- AUTO_ARIMA_WEEK1_list$Alabama[['cases']] # get the abs_error
my_forecasts<- AUTO_ARIMA_WEEK1_list$Alabama[['forecasts']] # get the number of models
my_abs_error<- AUTO_ARIMA_WEEK1_list$Alabama[['abs_error']] # get the abs_error
my_number_of_models<- AUTO_ARIMA_WEEK1_list$Alabama[['Number_of_models']] # get the number of models
my_dates<- AUTO_ARIMA_WEEK1_list$Alabama[['target_end_date']] # get the dates

# Here we will take a look at the WIS for 3 different states
Alabama<- AUTO_ARIMA_WEEK1_list$Alabama[['WIS']] # get the actual cases
Colorado<- AUTO_ARIMA_WEEK1_list$Colorado[['WIS']] # get the forecasts
Montana<- AUTO_ARIMA_WEEK1_list$Montana[['WIS']] # get the forecasts

# Assuming your data is in a data frame with columns 'my_dates', 'my_cases', and 'my_wis'
wis_data <- data.frame(
  my_dates = my_dates, # Ensure dates are in Date format
  Alabama = Alabama,
  Colorado = Colorado,
  Montana= Montana# Take the absolute value of WIS
)

# Calculate the mean WIS
mean_Alabama <- round(mean(wis_data$Alabama), 6)
mean_Colorado <- round(mean(wis_data$Colorado), 6)
mean_Montana <- round(mean(wis_data$Montana), 6)

# Let's look at WIS data for 3 different states
ggplot(wis_data) +
  geom_line(aes(x = my_dates, y = Alabama, color = "Alabama")) + # Plot cases and set legend label
  geom_line(aes(x = my_dates, y = Colorado, color = "Colorado")) + # Plot cases and set legend label
  geom_line(aes(x = my_dates, y = Montana, color = "Montana")) + # Plot WIS and set legend label
  scale_color_manual(values = c("Alabama" = "red", "Colorado" = "blue","Montana" = "green")) + # Define colors
  labs(
    title = "AUTO ARIMA weighted interval scores (WIS) for each target week (1 Wk ahead)",
    x = "",
    y = "WIS",
    color = "States", # Title for the legend
    subtitle = paste("MEAN WIS at Alabama:", mean_Alabama, "Colorado:", mean_Colorado, "Montana:", mean_Montana)
  ) +
  theme_minimal()

```


------------
1 Week ahead
------------
```{r}
# Creating new columns with Epidemiological weeks based on target_end_week
AUTO_ARIMA_WEEK1$epiweek <- MMWRweek(AUTO_ARIMA_WEEK1$target_end_date)$MMWRweek
AUTO_ADJACENT_WEEK1$epiweek <- MMWRweek(AUTO_ADJACENT_WEEK1$target_end_date)$MMWRweek
AUTO_EPIWEEK_WEEK1$epiweek <- MMWRweek(AUTO_EPIWEEK_WEEK1$target_end_date)$MMWRweek
AUTO_TEMPERATURE_WEEK1$epiweek <- MMWRweek(AUTO_TEMPERATURE_WEEK1$target_end_date)$MMWRweek
ES27_ARIMA_WEEK1$epiweek <- MMWRweek(ES27_ARIMA_WEEK1$target_end_date)$MMWRweek
ES27_ADJACENT_WEEK1$epiweek <- MMWRweek(ES27_ADJACENT_WEEK1$target_end_date)$MMWRweek
ES27_EPIWEEK_WEEK1$epiweek <- MMWRweek(ES27_EPIWEEK_WEEK1$target_end_date)$MMWRweek
ES27_TEMPERATURE_WEEK1$epiweek <- MMWRweek(ES27_TEMPERATURE_WEEK1$target_end_date)$MMWRweek
ES64_ARIMA_WEEK1$epiweek <- MMWRweek(ES64_ARIMA_WEEK1$target_end_date)$MMWRweek
ES64_ADJACENT_WEEK1$epiweek <- MMWRweek(ES64_ADJACENT_WEEK1$target_end_date)$MMWRweek
ES64_EPIWEEK_WEEK1$epiweek <- MMWRweek(ES64_EPIWEEK_WEEK1$target_end_date)$MMWRweek
ES64_TEMPERATURE_WEEK1$epiweek <- MMWRweek(ES64_TEMPERATURE_WEEK1$target_end_date)$MMWRweek

# Dataframe that will be analysed for 1 Week Ahead
df_W1 <- data.frame(
  STATE = AUTO_ARIMA_WEEK1$State,
  Julian_date = AUTO_ARIMA_WEEK1$target_end_date,
  epiweek = AUTO_ARIMA_WEEK1$epiweek,
  AUTO_AR=AUTO_ARIMA_WEEK1$WIS, 
  AUTO_ADJ=AUTO_ADJACENT_WEEK1$WIS, 
  AUTO_EPI=AUTO_EPIWEEK_WEEK1$WIS,
  AUTO_TEMP=AUTO_TEMPERATURE_WEEK1$WIS,
  ES27_AR=ES27_ARIMA_WEEK1$WIS, 
  ES27_ADJ=ES27_ADJACENT_WEEK1$WIS, 
  ES27_EPI=ES27_EPIWEEK_WEEK1$WIS,
  ES27_TEMP=ES27_TEMPERATURE_WEEK1$WIS,
  ES64_AR=ES64_ARIMA_WEEK1$WIS, 
  ES64_ADJ=ES64_ADJACENT_WEEK1$WIS, 
  ES64_EPI=ES64_EPIWEEK_WEEK1$WIS,
  ES64_TEMP=ES64_TEMPERATURE_WEEK1$WIS
)

head(df_W1)
```

------------
2 Weeks ahead
-------------
```{r}
# Creating new columns with Epidemiological weeks based on target_end_week
AUTO_ARIMA_WEEK2$epiweek <- MMWRweek(AUTO_ARIMA_WEEK2$target_end_date)$MMWRweek
AUTO_ADJACENT_WEEK2$epiweek <- MMWRweek(AUTO_ADJACENT_WEEK2$target_end_date)$MMWRweek
AUTO_EPIWEEK_WEEK2$epiweek <- MMWRweek(AUTO_EPIWEEK_WEEK2$target_end_date)$MMWRweek
AUTO_TEMPERATURE_WEEK2$epiweek <- MMWRweek(AUTO_TEMPERATURE_WEEK2$target_end_date)$MMWRweek
ES27_ARIMA_WEEK2$epiweek <- MMWRweek(ES27_ARIMA_WEEK2$target_end_date)$MMWRweek
ES27_ADJACENT_WEEK2$epiweek <- MMWRweek(ES27_ADJACENT_WEEK2$target_end_date)$MMWRweek
ES27_EPIWEEK_WEEK2$epiweek <- MMWRweek(ES27_EPIWEEK_WEEK2$target_end_date)$MMWRweek
ES27_TEMPERATURE_WEEK2$epiweek <- MMWRweek(ES27_TEMPERATURE_WEEK2$target_end_date)$MMWRweek
ES64_ARIMA_WEEK2$epiweek <- MMWRweek(ES64_ARIMA_WEEK2$target_end_date)$MMWRweek
ES64_ADJACENT_WEEK2$epiweek <- MMWRweek(ES64_ADJACENT_WEEK2$target_end_date)$MMWRweek
ES64_EPIWEEK_WEEK2$epiweek <- MMWRweek(ES64_EPIWEEK_WEEK2$target_end_date)$MMWRweek
ES64_TEMPERATURE_WEEK2$epiweek <- MMWRweek(ES64_TEMPERATURE_WEEK2$target_end_date)$MMWRweek

# Dataframe that will be analysed for 2 Weeks Ahead
df_W2 <- data.frame(
  STATE = AUTO_ARIMA_WEEK2$State,
  Julian_date = AUTO_ARIMA_WEEK2$target_end_date,
  epiweek = AUTO_ARIMA_WEEK2$epiweek,
  AUTO_AR=AUTO_ARIMA_WEEK2$WIS, 
  AUTO_ADJ=AUTO_ADJACENT_WEEK2$WIS, 
  AUTO_EPI=AUTO_EPIWEEK_WEEK2$WIS,
  AUTO_TEMP=AUTO_TEMPERATURE_WEEK2$WIS,
  ES27_AR=ES27_ARIMA_WEEK2$WIS, 
  ES27_ADJ=ES27_ADJACENT_WEEK2$WIS, 
  ES27_EPI=ES27_EPIWEEK_WEEK2$WIS,
  ES27_TEMP=ES27_TEMPERATURE_WEEK2$WIS,
  ES64_AR=ES64_ARIMA_WEEK2$WIS, 
  ES64_ADJ=ES64_ADJACENT_WEEK2$WIS, 
  ES64_EPI=ES64_EPIWEEK_WEEK2$WIS,
  ES64_TEMP=ES64_TEMPERATURE_WEEK2$WIS
)

head(df_W2)
```

-------------
3 Weeks ahead
-------------
```{r}
# Creating new columns with Epidemiological weeks based on target_end_week
AUTO_ARIMA_WEEK3$epiweek <- MMWRweek(AUTO_ARIMA_WEEK3$target_end_date)$MMWRweek
AUTO_ADJACENT_WEEK3$epiweek <- MMWRweek(AUTO_ADJACENT_WEEK3$target_end_date)$MMWRweek
AUTO_EPIWEEK_WEEK3$epiweek <- MMWRweek(AUTO_EPIWEEK_WEEK3$target_end_date)$MMWRweek
AUTO_TEMPERATURE_WEEK3$epiweek <- MMWRweek(AUTO_TEMPERATURE_WEEK3$target_end_date)$MMWRweek
ES27_ARIMA_WEEK3$epiweek <- MMWRweek(ES27_ARIMA_WEEK3$target_end_date)$MMWRweek
ES27_ADJACENT_WEEK3$epiweek <- MMWRweek(ES27_ADJACENT_WEEK3$target_end_date)$MMWRweek
ES27_EPIWEEK_WEEK3$epiweek <- MMWRweek(ES27_EPIWEEK_WEEK3$target_end_date)$MMWRweek
ES27_TEMPERATURE_WEEK3$epiweek <- MMWRweek(ES27_TEMPERATURE_WEEK3$target_end_date)$MMWRweek
ES64_ARIMA_WEEK3$epiweek <- MMWRweek(ES64_ARIMA_WEEK3$target_end_date)$MMWRweek
ES64_ADJACENT_WEEK3$epiweek <- MMWRweek(ES64_ADJACENT_WEEK3$target_end_date)$MMWRweek
ES64_EPIWEEK_WEEK3$epiweek <- MMWRweek(ES64_EPIWEEK_WEEK3$target_end_date)$MMWRweek
ES64_TEMPERATURE_WEEK3$epiweek <- MMWRweek(ES64_TEMPERATURE_WEEK3$target_end_date)$MMWRweek

# Dataframe that will be analysed for 3 Weeks Ahead
df_W3 <- data.frame(
  STATE = AUTO_ARIMA_WEEK3$State,
  Julian_date = AUTO_ARIMA_WEEK3$target_end_date,
  epiweek = AUTO_ARIMA_WEEK3$epiweek,
  AUTO_AR=AUTO_ARIMA_WEEK3$WIS, 
  AUTO_ADJ=AUTO_ADJACENT_WEEK3$WIS, 
  AUTO_EPI=AUTO_EPIWEEK_WEEK3$WIS,
  AUTO_TEMP=AUTO_TEMPERATURE_WEEK3$WIS,
  ES27_AR=ES27_ARIMA_WEEK3$WIS, 
  ES27_ADJ=ES27_ADJACENT_WEEK3$WIS, 
  ES27_EPI=ES27_EPIWEEK_WEEK3$WIS,
  ES27_TEMP=ES27_TEMPERATURE_WEEK3$WIS,
  ES64_AR=ES64_ARIMA_WEEK3$WIS, 
  ES64_ADJ=ES64_ADJACENT_WEEK3$WIS, 
  ES64_EPI=ES64_EPIWEEK_WEEK3$WIS,
  ES64_TEMP=ES64_TEMPERATURE_WEEK3$WIS
)

head(df_W3)
```

-------------
4 Weeks ahead
-------------
```{r}
# Creating new columns with Epidemiological weeks based on target_end_week
AUTO_ARIMA_WEEK4$epiweek <- MMWRweek(AUTO_ARIMA_WEEK4$target_end_date)$MMWRweek
AUTO_ADJACENT_WEEK4$epiweek <- MMWRweek(AUTO_ADJACENT_WEEK4$target_end_date)$MMWRweek
AUTO_EPIWEEK_WEEK4$epiweek <- MMWRweek(AUTO_EPIWEEK_WEEK4$target_end_date)$MMWRweek
AUTO_TEMPERATURE_WEEK4$epiweek <- MMWRweek(AUTO_TEMPERATURE_WEEK4$target_end_date)$MMWRweek
ES27_ARIMA_WEEK4$epiweek <- MMWRweek(ES27_ARIMA_WEEK4$target_end_date)$MMWRweek
ES27_ADJACENT_WEEK4$epiweek <- MMWRweek(ES27_ADJACENT_WEEK4$target_end_date)$MMWRweek
ES27_EPIWEEK_WEEK4$epiweek <- MMWRweek(ES27_EPIWEEK_WEEK4$target_end_date)$MMWRweek
ES27_TEMPERATURE_WEEK4$epiweek <- MMWRweek(ES27_TEMPERATURE_WEEK4$target_end_date)$MMWRweek
ES64_ARIMA_WEEK4$epiweek <- MMWRweek(ES64_ARIMA_WEEK4$target_end_date)$MMWRweek
ES64_ADJACENT_WEEK4$epiweek <- MMWRweek(ES64_ADJACENT_WEEK4$target_end_date)$MMWRweek
ES64_EPIWEEK_WEEK4$epiweek <- MMWRweek(ES64_EPIWEEK_WEEK4$target_end_date)$MMWRweek
ES64_TEMPERATURE_WEEK4$epiweek <- MMWRweek(ES64_TEMPERATURE_WEEK4$target_end_date)$MMWRweek

# Dataframe that will be analysed for 4 Weeks Ahead
df_W4 <- data.frame(
  STATE = AUTO_ARIMA_WEEK4$State,
  Julian_date = AUTO_ARIMA_WEEK4$target_end_date,
  epiweek = AUTO_ARIMA_WEEK4$epiweek,
  AUTO_AR=AUTO_ARIMA_WEEK4$WIS, 
  AUTO_ADJ=AUTO_ADJACENT_WEEK4$WIS, 
  AUTO_EPI=AUTO_EPIWEEK_WEEK4$WIS,
  AUTO_TEMP=AUTO_TEMPERATURE_WEEK4$WIS,
  ES27_AR=ES27_ARIMA_WEEK4$WIS, 
  ES27_ADJ=ES27_ADJACENT_WEEK4$WIS, 
  ES27_EPI=ES27_EPIWEEK_WEEK4$WIS,
  ES27_TEMP=ES27_TEMPERATURE_WEEK4$WIS,
  ES64_AR=ES64_ARIMA_WEEK4$WIS, 
  ES64_ADJ=ES64_ADJACENT_WEEK4$WIS, 
  ES64_EPI=ES64_EPIWEEK_WEEK4$WIS,
  ES64_TEMP=ES64_TEMPERATURE_WEEK4$WIS
)

head(df_W4)
```

Filter only the flu season

```{r}
# Filter the dataframe for epiweek >= 40 or epiweek <= 20
filtered_df_W1 <- df_W1 %>%
  filter(epiweek >= 40 | epiweek <= 20)

# Display the filtered dataset
head(filtered_df_W1)


# Filter the dataframe for epiweek >= 40 or epiweek <= 20
filtered_df_W2 <- df_W2 %>%
  filter(epiweek >= 40 | epiweek <= 20)

# Display the filtered dataset
head(filtered_df_W2)

# Filter the dataframe for epiweek >= 40 or epiweek <= 20
filtered_df_W3 <- df_W3 %>%
  filter(epiweek >= 40 | epiweek <= 20)

# Display the filtered dataset
head(filtered_df_W3)

# Filter the dataframe for epiweek >= 40 or epiweek <= 20
filtered_df_W4 <- df_W4 %>%
  filter(epiweek >= 40 | epiweek <= 20)

# Display the filtered dataset
head(filtered_df_W1)
```

Calculate mean weighted interval score for all forecast weeks on each model.

```{r}

# Define the function
calculate_mean_wis <- function(data) {
  data %>%
    group_by(STATE) %>%
    summarize(
      AUTO_AR = mean(AUTO_AR, na.rm = TRUE),
      AUTO_ADJ = mean(AUTO_ADJ, na.rm = TRUE),
      AUTO_EPI = mean(AUTO_EPI, na.rm = TRUE),
      AUTO_TMP = mean(AUTO_TEMP, na.rm = TRUE),
      ES27_AR = mean(ES27_AR, na.rm = TRUE),
      ES27_ADJ = mean(ES27_ADJ, na.rm = TRUE),
      ES27_EPI = mean(ES27_EPI, na.rm = TRUE),
      ES27_TMP = mean(ES27_TEMP, na.rm = TRUE),
      ES64_AR = mean(ES64_AR, na.rm = TRUE),
      ES64_ADJ = mean(ES64_ADJ, na.rm = TRUE),
      ES64_EPI = mean(ES64_EPI, na.rm = TRUE),
      ES64_TMP = mean(ES64_TEMP, na.rm = TRUE)
    )
}

# Now you can use the function with any dataframe
W1 <- calculate_mean_wis(filtered_df_W1)
W2 <- calculate_mean_wis(filtered_df_W2)
W3 <- calculate_mean_wis(filtered_df_W3)
W4 <- calculate_mean_wis(filtered_df_W4)

# Display the resulting dataframe
head(W1)
head(W2)
head(W3)
head(W4)
```

Here we have boxplots of the mean(WIS) by each state. 

```{r}
# Combine the data into one data frame
combined_data <- data.frame(
  week = rep(c("W1", "W2", "W3", "W4"), each = 47 * 12),
  
  variable = rep(c("AUTO_AR", "ES27_AR", "ES64_AR", "AUTO_ADJ", "ES27_ADJ", "ES64_ADJ", "AUTO_TMP", "ES27_TMP", "ES64_TMP", "AUTO_EPI", "ES27_EPI", "ES64_EPI"), each=47, times = 4),
  
  value = c(W1$AUTO_AR, W1$ES27_AR, W1$ES64_AR, W1$AUTO_ADJ, W1$ES27_ADJ, W1$ES64_ADJ, W1$AUTO_TMP, W1$ES27_TMP, W1$ES64_TMP, W1$AUTO_EPI, W1$ES27_EPI, W1$ES64_EPI,
            W2$AUTO_AR, W2$ES27_AR, W2$ES64_AR, W2$AUTO_ADJ, W2$ES27_ADJ, W2$ES64_ADJ, W2$AUTO_TMP, W2$ES27_TMP, W2$ES64_TMP, W2$AUTO_EPI, W2$ES27_EPI, W2$ES64_EPI,
            W3$AUTO_AR, W3$ES27_AR, W3$ES64_AR, W3$AUTO_ADJ, W3$ES27_ADJ, W3$ES64_ADJ, W3$AUTO_TMP, W3$ES27_TMP, W3$ES64_TMP, W3$AUTO_EPI, W3$ES27_EPI, W3$ES64_EPI,
            W4$AUTO_AR, W4$ES27_AR, W4$ES64_AR, W4$AUTO_ADJ, W4$ES27_ADJ, W4$ES64_ADJ, W4$AUTO_TMP, W4$ES27_TMP, W4$ES64_TMP, W4$AUTO_EPI, W4$ES27_EPI, W4$ES64_EPI)
)

# Create a new column for categories
combined_data <- combined_data %>%
  mutate(category = case_when(
    grepl("AR", variable) ~ "AR",
    grepl("EPI", variable) ~ "EPI",
    grepl("TMP", variable) ~ "TMP",
    grepl("ADJ", variable) ~ "ADJ"
  ))

# Define color ramps for each category
colors_ar <- c("#a6cee3","#226e83", "#08306b")
colors_adj <- c("#fb9a99","red3", "#a11c3e")
colors_epi <- c("#cab2d6", "purple2", "#5e2b7b")
colors_tmp <- c("lightgreen","green3","#319045")

# Create a custom color mapping for each variable
custom_colors <- c(
  "AUTO_AR" = colors_ar[1], "ES27_AR" = colors_ar[2], "ES64_AR" = colors_ar[3],
  "AUTO_EPI" = colors_epi[1], "ES27_EPI" = colors_epi[2], "ES64_EPI" = colors_epi[3],
  "AUTO_TMP" = colors_tmp[1], "ES27_TMP" = colors_tmp[2], "ES64_TMP" = colors_tmp[3],
  "AUTO_ADJ" = colors_adj[1], "ES27_ADJ" = colors_adj[2], "ES64_ADJ" = colors_adj[3]
)

  # Create the box plot with additional facet for categories
  ggplot(combined_data, aes(x = week, y = value, fill = variable)) +
    geom_boxplot(color = "black") +
    scale_fill_manual(values = custom_colors) +
    facet_wrap(category ~ variable , nrow = 2) +
    labs(
      title = "Models' mean(WIS) for 47 U.S. states by weeks ahead",
      x = "",
      y = "Weighted Interval Score (WIS)"
    ) +
    theme_minimal()
  
  # Create the box plot with additional facet for categories
  ggplot(combined_data, aes(x = week, y = log(value), fill = variable)) +
    geom_boxplot(color = "black") +
    scale_fill_manual(values = custom_colors) +
    facet_wrap(category ~ variable , nrow = 2) +
    labs(
      title = "Models' mean(WIS) for 47 U.S. states by weeks ahead on a log-scale",
      x = "",
      y = "log(WIS)"
    ) +
    theme_minimal()

```

Here I include a column with the best model result based on the lowest mean(WIS) of each state.

```{r}
# BEST RESULT

# Extract the columns of interest 
cols <- colnames(W1)[-1]
# Initialize a vector to store results
W1$Best_Result <- character(nrow(W1))

# Give me the model with lower WIS value in the best result column
for (i in 1:nrow(W1)) {
  # Find the column name with the minimum value for each row
  W1$Best_Result[i] <- cols[which.min(W1[i, cols])]
}

# REORDER BY FREQUENCY
W1$Best_Result <- fct_infreq(W1$Best_Result)

# Print merged results
head(W1)

################################################

# Extract the columns of interest 
cols <- colnames(W2)[-1]
# Initialize a vector to store results
W2$Best_Result <- character(nrow(W2))
# Give me the model with lower WIS value in the best result column
for (i in 1:nrow(W2)) {
  # Find the column name with the minimum value for each row
  W2$Best_Result[i] <- cols[which.min(W2[i, cols])]
}

# REORDER BY FREQUENCY
W2$Best_Result <- fct_infreq(W2$Best_Result)

# Print merged results
head(W2)

######################################
# BEST RESULT
# Extract the columns of interest 
cols <- colnames(W3)[-1]
# Initialize a vector to store results
W3$Best_Result <- character(nrow(W3))

# Give me the model with lower WIS value in the best result column
for (i in 1:nrow(W3)) {
  # Find the column name with the minimum value for each row
  W3$Best_Result[i] <- cols[which.min(W3[i, cols])]
}

# REORDER BY FREQUENCY
W3$Best_Result <- fct_infreq(W3$Best_Result)

# Print merged results
head(W3)

###################################
# BEST RESULT
# Extract the columns of interest
cols <- colnames(W4)[-1]
# Initialize a vector to store results
W4$Best_Result <- character(nrow(W4))
# Give me the model with lower WIS value in the best result column
for (i in 1:nrow(W4)) {
  # Find the column name with the minimum value for each row
  W4$Best_Result[i] <- cols[which.min(W4[i, cols])]
}
W4$Best_Result <- fct_infreq(W4$Best_Result)

# Print merged results
head(W4)

```

Now, let's plot the best models by each state for each forecast horizon (1-4 weeks ahead). 

```{r}
# --------- WEEK1 MODELS ------------- #
ggplot(W1, aes(x = Best_Result, fill = Best_Result)) +
  geom_bar() +
  scale_fill_manual(values = custom_colors) +
  labs(title = "Best Model based on mean(WIS) for 47 U.S. states (1 Week Ahead)",
       x = "", y = "Number of states") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# --------- WEEK2 MODELS ------------- #
ggplot(W2, aes(x = Best_Result, fill = Best_Result)) +
  geom_bar() +
  scale_fill_manual(values = custom_colors) +
  labs(title = "Best Model based on mean(WIS) for 47 U.S. states (2 Weeks Ahead)",
       x = "", y = "Number of states") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# --------- WEEK3 MODELS ------------- #
ggplot(W3, aes(x = Best_Result, fill = Best_Result)) +
  geom_bar() +
  scale_fill_manual(values = custom_colors) +
  labs(title = "Best Model based on mean(WIS) for 47 U.S. states (3 Weeks Ahead)",
       x = "", y = "Number of states") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
 
# --------- WEEK4 MODELS ------------- #
ggplot(W4, aes(x = Best_Result, fill = Best_Result)) +
  geom_bar() +
  scale_fill_manual(values = custom_colors) +
  labs(title = "Best Model based on mean(WIS) for 47 U.S. states (4 Weeks Ahead)",
       x = "", y = "Number of states") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

This plot combines the 4 forecast horizons and the counts of best models in a single plot.

```{r}
models <- readr::read_csv("models.csv") %>% 
  mutate(ex.var = factor(ex.var,
                         levels = c("none",
                                    "mean of ILI in adjacent states in previous week",
                                    "temperature",
                                    "mean of ILI in epiweek - 52 and ILI in epiweek - 104")
                         )
         )

thegrid <- expand_grid(model = models$model, target=paste0("W",1:4))

BestResults <- W1 %>% select(STATE, W1 = Best_Result) %>% 
  full_join(W2 %>% select(STATE, W2 = Best_Result)) %>%  
  full_join(W3 %>% select(STATE, W3 = Best_Result)) %>%  
  full_join(W4 %>% select(STATE, W4 = Best_Result)) %>% 
  pivot_longer(-STATE, names_to = "target", values_to = "Best_Result") %>% 
  group_by(target, Best_Result) %>% 
  summarise(n_best = n()) %>% 
  rename(model = Best_Result) %>% 
  ungroup() %>% 
  # complete(target, model) %>% 
  full_join(thegrid, by = c("target", "model")) %>% 
  full_join(models) %>% 
  replace_na(list(n_best = 0))


g <- BestResults %>% 
  arrange(ex.var) %>% 
  ggplot(aes(x=factor(model,
                      levels = models %>% arrange(ensemble.size, ex.var) %>% pull(model)), 
             y=n_best, 
             group=target, 
             fill=ex.var,
             alpha=target)) + 
  geom_bar(
           position="dodge",
           stat='identity') +
  
  labs(title = "Best Model based on WIS for 47 U.S. states (1 to 4 Weeks Ahead)",
       x = "", y="Number of states for which model is best") +
  theme_bw() +
  scale_alpha_manual(values=c(.4,.6,.8,1), na.translate = FALSE) +
  scale_fill_manual(values=c("#08306b","red3","#319045","#5e2b7b"),
                    na.translate = FALSE) +
  theme(panel.grid.major.x = element_blank(),
        axis.ticks.x = element_blank(), 
        axis.text.x = element_text(angle = 45, size = 7, vjust = 0.5, hjust=1),
        strip.placement = "outside", 
        strip.background = element_rect(fill=NA,colour="grey50"),
        panel.spacing=unit(0,"cm"),
        legend.position="none")  # This line removes the legend
g

#g %>% plotly::ggplotly()
```

Now let's plot maps with the best models we found for each state based on the best mean(WIS).

```{r}
#################################################
# ES27 ARIMAX by ADJACENT STATES - 1 WEEK AHEAD #
#################################################

category_colors <- c(
  "AUTO_AR" = "#a6cee3", "ES27_AR" = "#226e83", "ES64_AR" = "#08306b",
  "AUTO_ADJ" = "#fb9a99", "ES27_ADJ" = "red3", "ES64_ADJ" = "#a11c3e",
  "AUTO_TMP" = "lightgreen", "ES27_TMP" = "green3", "ES64_TMP" = "#319045",
  "AUTO_EPI" = "#cab2d6", "ES27_EPI" = "purple2", "ES64_EPI" = "#5e2b7b"
)

map_week1<-left_join(states, W1, by=join_by("STATE"))%>%
  drop_na()

ES_1WEEK<- ggplot(map_week1, fill ="lightgrey") +  theme_light()  + geom_sf(aes(fill=Best_Result)) +  scale_fill_manual(values = category_colors) +  ggtitle("Best model based on mean(WIS) (1 Week Ahead)")

x_limits <- c(-130, -65)  # Set the desired longitude range
y_limits <- c(20, 55)    # Set the desired latitude range

ES_1WEEK + coord_sf(xlim = x_limits, ylim = y_limits)

###################################################
# ES27 ARIMAX by ADJACENT STATES - 2 WEEKS AHEAD #
#################################################

map_week2<-left_join(states, W2, by=join_by("STATE"))%>%
  drop_na()

MAP_WEEK2<- ggplot(map_week2, fill ="lightgrey") +  theme_light()  + geom_sf(aes(fill=Best_Result)) +  scale_fill_manual(values = category_colors) +  ggtitle("Best model based on mean(WIS) (2 Weeks Aheads)")

x_limits <- c(-130, -65)  # Set the desired longitude range
y_limits <- c(20, 55)    # Set the desired latitude range

MAP_WEEK2 + coord_sf(xlim = x_limits, ylim = y_limits)

###################################################
# ES27 ARIMAX by ADJACENT STATES - 3 WEEKS AHEAD #
#################################################

map_week3<-left_join(states, W3, by=join_by("STATE"))%>%
  drop_na()

MAP_WEEK3<- ggplot(map_week3, fill ="lightgrey") +  theme_light()  + geom_sf(aes(fill=Best_Result)) +  scale_fill_manual(values = category_colors) +  ggtitle("Best model based on mean(WIS) (3 Weeks Aheads)")

x_limits <- c(-130, -65)  # Set the desired longitude range
y_limits <- c(20, 55)    # Set the desired latitude range

MAP_WEEK3 + coord_sf(xlim = x_limits, ylim = y_limits)  

###################################################
# ES27 ARIMAX by ADJACENT STATES - 4 WEEKS AHEAD #
#################################################

map_week4<-left_join(states, W4, by=join_by("STATE"))%>%
  drop_na()

MAP_WEEK4<- ggplot(map_week4, fill ="lightgrey") +  theme_light()  + geom_sf(aes(fill=Best_Result)) +  scale_fill_manual(values = category_colors) +  ggtitle("Best model based on mean(WIS) (4 Weeks Aheads)")

x_limits <- c(-130, -65)  # Set the desired longitude range
y_limits <- c(20, 55)    # Set the desired latitude range

MAP_WEEK4 + coord_sf(xlim = x_limits, ylim = y_limits) 
```

Now, let's map the mean(WIS) for the AUTO ARIMA model as an example. 

```{r}

# Calculate breaks dynamically or use a fixed range
data_range <- c(0,400)# 
breaks <- pretty(data_range, n = 6)  # breaks
labels <- breaks  # 

# Define color palette
colors <- colorRampPalette(c("#08306b", "white", "red3"))(100)

MAP_WEEK1 <- ggplot(map_week1) + 
    theme_light() + 
    geom_sf(aes(fill = (AUTO_AR)), color = "black") + 
    scale_fill_gradientn(
        "mean(WIS)",
        colors = colors,
        breaks = breaks,
        labels = labels,
        limits = data_range,
        na.value = "lightgrey"
    ) + 
    ggtitle("MEAN WIS AUTO ARIMA (1 Wk)") + 
    labs(subtitle = "Prevalence: ILI Cases/State Population") +  # Add your subtitle here
    coord_sf(xlim = c(-130, -65), ylim = c(20, 55)) + 
    theme(legend.position = "right")

# Print the map
print(MAP_WEEK1)


# Create the map
MAP_WEEK2 <- ggplot(map_week2) + 
  theme_light() + 
  geom_sf(aes(fill = AUTO_AR), color = "black") + 
  scale_fill_gradientn(
    "mean(WIS)", 
    colors = colors,
    breaks = breaks,
    labels = labels,
    limits = data_range,
    na.value = "lightgrey"  
  ) + 
    ggtitle("MEAN WIS AUTO ARIMA (2 Wk)") + 
    labs(subtitle = "Prevalence: ILI Cases/State Population") +  # Add your subtitle here
  coord_sf(xlim = c(-130, -65), ylim = c(20, 55)) + 
  theme(legend.position = "right")

# Print the map
print(MAP_WEEK2)

################################

MAP_WEEK3 <- ggplot(map_week3) + 
  theme_light() + 
  geom_sf(aes(fill = AUTO_AR), color = "black") + 
  scale_fill_gradientn(
    "mean(WIS)", 
    colors = colors,
    breaks = breaks,
    labels = labels,
    limits = data_range,
    na.value = "lightgrey"  
  ) + 
    ggtitle("MEAN WIS AUTO ARIMA (3 Wk)") + 
  labs(subtitle = "Prevalence: ILI Cases/State Population") +  # Add your subtitle here
  coord_sf(xlim = c(-130, -65), ylim = c(20, 55)) + 
  theme(legend.position = "right")

# Print the map
print(MAP_WEEK3)

#######################
MAP_WEEK4 <- ggplot(map_week4) + 
  theme_light() + 
  geom_sf(aes(fill = AUTO_AR), color = "black") + 
  scale_fill_gradientn(
    "mean(WIS)", 
    colors = colors,
    breaks = breaks,
    labels = labels,
    limits = data_range,
    na.value = "lightgrey"  
  ) + 
  ggtitle("MEAN WIS AUTO ARIMA (4 Wk)") + 
  labs(subtitle = "Prevalence: ILI Cases/State Population") +  # Add your subtitle here
  coord_sf(xlim = c(-130, -65), ylim = c(20, 55)) + 
  theme(legend.position = "right")

# Print the map
print(MAP_WEEK4)

```

Let's plot the same map on a log scale for better visualization.

```{r}

# Calculate breaks dynamically or use a fixed range
data_range <- c(0,7)# 
breaks <- pretty(data_range, n = 6)  # breaks
labels <- breaks  # 

# Define color palette
colors <- colorRampPalette(c("#08306b", "white", "red3"))(100)

MAP_WEEK1 <- ggplot(map_week1) + 
    theme_light() + 
    geom_sf(aes(fill =log(AUTO_AR)), color = "black") + 
    scale_fill_gradientn(
        "log(MEAN WIS)",
        colors = colors,
        breaks = breaks,
        labels = labels,
        limits = data_range,
        na.value = "lightgrey"
    ) + 
    ggtitle("log(MEAN WIS) AUTO ARIMA (1 Wk)") + 
    labs(subtitle = "Prevalence: ILI Cases/State Population") +  # Add your subtitle here
    coord_sf(xlim = c(-130, -65), ylim = c(20, 55)) + 
    theme(legend.position = "right")

# Print the map
print(MAP_WEEK1)


# Create the map
MAP_WEEK2 <- ggplot(map_week2) + 
  theme_light() + 
  geom_sf(aes(fill = log(AUTO_AR)), color = "black") + 
  scale_fill_gradientn(
    "log(MEAN WIS)", 
    colors = colors,
    breaks = breaks,
    labels = labels,
    limits = data_range,
    na.value = "lightgrey"  
  ) + 
    ggtitle("log(MEAN WIS) AUTO ARIMA (2 Wk)") + 
    labs(subtitle = "Prevalence: ILI Cases/State Population") +  # Add your subtitle here
  coord_sf(xlim = c(-130, -65), ylim = c(20, 55)) + 
  theme(legend.position = "right")

# Print the map
print(MAP_WEEK2)

################################

MAP_WEEK3 <- ggplot(map_week3) + 
  theme_light() + 
  geom_sf(aes(fill = log(AUTO_AR)), color = "black") + 
  scale_fill_gradientn(
    "log(MEAN WIS)", 
    colors = colors,
    breaks = breaks,
    labels = labels,
    limits = data_range,
    na.value = "lightgrey"  
  ) + 
    ggtitle("log(MEAN WIS) AUTO ARIMA (3 Wk)") + 
  labs(subtitle = "Prevalence: ILI Cases/State Population") +  # Add your subtitle here
  coord_sf(xlim = c(-130, -65), ylim = c(20, 55)) + 
  theme(legend.position = "right")

# Print the map
print(MAP_WEEK3)

#######################
MAP_WEEK4 <- ggplot(map_week4) + 
  theme_light() + 
  geom_sf(aes(fill = log(AUTO_AR)), color = "black") + 
  scale_fill_gradientn(
    "log(MEAN WIS)", 
    colors = colors,
    breaks = breaks,
    labels = labels,
    limits = data_range,
    na.value = "lightgrey"  
  ) + 
  ggtitle("log(MEAN WIS) AUTO ARIMA (4 Wk)") + 
  labs(subtitle = "Prevalence: ILI Cases/State Population") +  # Add your subtitle here
  coord_sf(xlim = c(-130, -65), ylim = c(20, 55)) + 
  theme(legend.position = "right")

# Print the map
print(MAP_WEEK4)

```

Let's calculate the mean(WIS) improvement relative to the AUTO ARIMA model. We will compare each model with the AUTO ARIMA model for the same states. Later we sum the results of these comparisons. Positive results indicate that there was a general improvement in the mean(WIS) for a given model type among all states. Note that larger values on specific states may override a general trend and make the results less informative. So I do not strongly advice this analysis.

```{r}
calculate_percentage_of_improvement <- function(data) {
  return(data.frame(
    AUTO_AR = (data$AUTO_AR - data$AUTO_AR),
    ES27_AR = ((data$AUTO_AR - data$ES27_AR) / data$AUTO_AR) * 100,
    ES64_AR = ((data$AUTO_AR - data$ES64_AR) / data$AUTO_AR) * 100,
    AUTO_ADJ = ((data$AUTO_AR - data$AUTO_ADJ) / data$AUTO_AR) * 100,
    ES27_ADJ = ((data$AUTO_AR - data$ES27_ADJ) / data$AUTO_AR) * 100,
    ES64_ADJ = ((data$AUTO_AR - data$ES64_ADJ) / data$AUTO_AR) * 100,
    AUTO_TMP = ((data$AUTO_AR - data$AUTO_TMP) / data$AUTO_AR) * 100,
    ES27_TMP = ((data$AUTO_AR - data$ES27_TMP) / data$AUTO_AR) * 100,
    ES64_TMP = ((data$AUTO_AR - data$ES64_TMP) / data$AUTO_AR) * 100,
    AUTO_EPI = ((data$AUTO_AR - data$AUTO_EPI) / data$AUTO_AR) * 100,
    ES27_EPI = ((data$AUTO_AR - data$ES27_EPI) / data$AUTO_AR) * 100,
    ES64_EPI = ((data$AUTO_AR - data$ES64_EPI) / data$AUTO_AR) * 100
  ))
}

# Calculate percentage of improvemtn 
W1_percentage_of_improvement <- calculate_percentage_of_improvement(W1)
W2_percentage_of_improvement <- calculate_percentage_of_improvement(W2)
W3_percentage_of_improvement <- calculate_percentage_of_improvement(W3)
W4_percentage_of_improvement <- calculate_percentage_of_improvement(W4)
```

Now let's plot a map of percentage of WIS improvement for each state.

```{r}
# MAP 1 week ahead

W1_map <- data.frame(
  STATE = W1$STATE,
  best_model = W1$Best_Result,
  percentage_improvement = apply(W1_percentage_of_improvement, 1, max)
)

# Merge the best model data with the states map
W1_map <- states %>%
  left_join(W1_map, by = c("STATE")) %>%
  filter(!is.na(percentage_improvement))

################################### MAP 2 weeka ahead

W2_map <- data.frame(
  STATE = W2$STATE,
  best_model = W2$Best_Result,
  percentage_improvement = apply(W2_percentage_of_improvement, 1, max)
)

# Merge the best model data with the states map
W2_map <- states %>%
  left_join(W2_map, by = c("STATE")) %>%
  filter(!is.na(percentage_improvement))


##################################### MAP 3 weeka ahead

W3_map <- data.frame(
  STATE = W3$STATE,
  best_model = W3$Best_Result,
  percentage_improvement = apply(W3_percentage_of_improvement, 1, max)
)

# Merge the best model data with the states map
W3_map <- states %>%
  left_join(W3_map, by = c("STATE")) %>%
  filter(!is.na(percentage_improvement))

############################### MAP 4 weeka ahead

W4_map <- data.frame(
  STATE = W4$STATE,
  best_model = W4$Best_Result,
  percentage_improvement = apply(W4_percentage_of_improvement, 1, max)
)

# Merge the best model data with the states map
W4_map <- states %>%
  left_join(W4_map, by = c("STATE")) %>%
  filter(!is.na(percentage_improvement))
```

Let's plot some maps with the best models in each state and the percentage of improvement compared to the AUTO ARIMA models for the same state.

Here I define some colors categories that I will use on the next maps.

```{r}

# Define colors for the modelss
category_colors <- c(
  "AUTO_AR" = "#a6cee3",
  "ES27_AR" = "#226e83",
  "ES64_AR" = "#08306b",
  "AUTO_ADJ" = "#fb9a99",
  "ES27_ADJ" = "red3",
  "ES64_ADJ" = "#a11c3e",
  "AUTO_TMP" = "lightgreen",
  "ES27_TMP" = "green3",
  "ES64_TMP" = "#319045",
  "AUTO_EPI" = "#cab2d6",
  "ES27_EPI" = "purple2",
  "ES64_EPI" = "#5e2b7b"
)
```

1 week ahead percentage of improvement

```{r}
# Assuming merged_data already includes the necessary columns: model and percentage_improveme
# Create the map plot for 1 Week Ahead with best models and percentage improvement
ES_1WEEK <- ggplot(W1_map) +
  geom_sf(aes(fill = best_model)) +  # Fill based on the best model
  scale_fill_manual(values = category_colors) +
  ggtitle("Best models and % of improvement compared to AUTO ARIMA (Wk1)") +
  theme_light() +
  theme(legend.position = "right") +
  geom_sf_text(data = W1_map, aes(label = round(percentage_improvement,1)),  # Round to whole numbers
               size = 3,
               color = "black",
               check_overlap = TRUE)+  # Display percentage improvement in each state
  labs(fill = "Model")  # Label for the legend

x_limits <- c(-125, -67)  # Set the desired longitude range
y_limits <- c(25, 50)    # Set the desired latitude range

ES_1WEEK + coord_sf(xlim = x_limits, ylim = y_limits)

```

Histogram of the percentage of improvement for all states - 1 week ahead

```{r}
# Assuming your data is in W4_map$percentage_improvement
# Create a new column to classify positive and negative values
W1_map$category <- ifelse(W1_map$percentage_improvement > 0, "Improved WIS", "Not Improved WIS")

# Create the ggplot histogram
ggplot(W1_map, aes(x = percentage_improvement, fill = category)) +
  geom_histogram(binwidth = 5, color = "white", boundary = 0) +  # Set bin width to 5
  scale_fill_manual(values = c("Improved WIS" = "blue", "Not Improved WIS" = "red")) +  # Color mapping
  scale_x_continuous(breaks = seq(-5, 35, by = 5), limits = c(-5, 35)) +  # Set x-axis breaks
  labs(title = "Mean WIS improvement % by each state compared to AUTO ARIMA (Wk1)",
       x = "Improvement % = (WIS AUTO_ARIMA - WIS BEST MODEL) / WIS AUTO_ARIMA)*100",
       y = "Frequency", fill=NULL) +
  theme_minimal()
```

2 weeks ahead

```{r}

# Assuming merged_data already includes the necessary columns: model and percentage_improveme
# Create the map plot for 1 Week Ahead with best models and percentage improvement
ES_2WEEK <- ggplot(W2_map) +
  geom_sf(aes(fill = best_model)) +  # Fill based on the best model
  scale_fill_manual(values = category_colors) +
  ggtitle("Best models and % of improvement compared to AUTO ARIMA (Wk2)") +
  theme_light() +
  theme(legend.position = "right") +
  geom_sf_text(data = W2_map, aes(label = round(percentage_improvement,1)),  # Round to whole numbers
               size = 3,
               color = "black",
               check_overlap = TRUE)+  # Display percentage improvement in each state
  labs(fill = "Model")  # Label for the legend

x_limits <- c(-125, -67)  # Set the desired longitude range
y_limits <- c(25, 50)    # Set the desired latitude range

ES_2WEEK + coord_sf(xlim = x_limits, ylim = y_limits)

```

Histogram of the percentage of improvement for all states - 2 weeks ahead

```{r}
# Assuming your data is in W4_map$percentage_improvement
# Create a new column to classify positive and negative values
W2_map$category <- ifelse(W2_map$percentage_improvement > 0, "Improved WIS", "Not Improved WIS")

# Create the ggplot histogram
ggplot(W2_map, aes(x = percentage_improvement, fill = category)) +
  geom_histogram(binwidth = 5, color = "white", boundary = 0) +  # Set bin width to 5
  scale_fill_manual(values = c("Improved WIS" = "blue", "Not Improved WIS" = "red")) +  # Color mapping
  scale_x_continuous(breaks = seq(-5, 35, by = 5), limits = c(-5, 35)) +  # Set x-axis breaks
  labs(title = "Mean WIS improvement % by each state compared to AUTO ARIMA (Wk2)",
       x = "Improvement % = (WIS AUTO_ARIMA - WIS BEST MODEL) / WIS AUTO_ARIMA)*100",
       y = "Frequency", fill=NULL) +
  theme_minimal()
```

3 weeks ahead

```{r}

# Assuming merged_data already includes the necessary columns: model and percentage_improveme
# Create the map plot for 1 Week Ahead with best models and percentage improvement
ES_3WEEK <- ggplot(W3_map) +
  geom_sf(aes(fill = best_model)) +  # Fill based on the best model
  scale_fill_manual(values = category_colors) +
  ggtitle("Best models and % of improvement compared to AUTO ARIMA (Wk3)") +
  theme_light() +
  theme(legend.position = "right") +
  geom_sf_text(data = W3_map, aes(label = round(percentage_improvement,1)),  # Round to whole numbers
               size = 3,
               color = "black",
               check_overlap = TRUE)+  # Display percentage improvement in each state
  labs(fill = "Model")  # Label for the legend

x_limits <- c(-125, -67)  # Set the desired longitude range
y_limits <- c(25, 50)    # Set the desired latitude range

ES_3WEEK + coord_sf(xlim = x_limits, ylim = y_limits)

```

Histogram of the percentage of improvement for all states - 3 weeks ahead

```{r}
# Assuming your data is in W4_map$percentage_improvement
# Create a new column to classify positive and negative values
W3_map$category <- ifelse(W3_map$percentage_improvement > 0, "Improved WIS", "Not Improved WIS")

# Create the ggplot histogram
ggplot(W3_map, aes(x = percentage_improvement, fill = category)) +
  geom_histogram(binwidth = 5, color = "white", boundary = 0) +  # Set bin width to 5
  scale_fill_manual(values = c("Improved WIS" = "blue", "Not Improved WIS" = "red")) +  # Color mapping
  scale_x_continuous(breaks = seq(-5, 35, by = 5), limits = c(-5, 35)) +  # Set x-axis breaks
  labs(title = "Mean WIS improvement % by each state compared to AUTO ARIMA (Wk3)",
       x = "Improvement % = (WIS AUTO_ARIMA - WIS BEST MODEL) / WIS AUTO_ARIMA)*100",
       y = "Frequency", fill=NULL) +
  theme_minimal()
```

4 weeks ahead

```{r}

# Assuming merged_data already includes the necessary columns: model and percentage_improveme
# Create the map plot for 1 Week Ahead with best models and percentage improvement
ES_4WEEK <- ggplot(W4_map) +
  geom_sf(aes(fill = best_model)) +  # Fill based on the best model
  scale_fill_manual(values = category_colors) +
  ggtitle("Best models and % of improvement compared to AUTO ARIMA (Wk4)") +
  theme_light() +
  theme(legend.position = "right") +
  geom_sf_text(data = W4_map, aes(label = round(percentage_improvement,1)),  # Round to whole numbers
               size = 3,
               color = "black",
               check_overlap = TRUE)+  # Display percentage improvement in each state
  labs(fill = "Model")  # Label for the legend

x_limits <- c(-125, -67)  # Set the desired longitude range
y_limits <- c(25, 50)    # Set the desired latitude range

ES_4WEEK + coord_sf(xlim = x_limits, ylim = y_limits)

```

Histogram of the percentage of improvement for all states - 4 weeks ahead

```{r}
# Assuming your data is in W4_map$percentage_improvement
# Create a new column to classify positive and negative values
W4_map$category <- ifelse(W4_map$percentage_improvement > 0, "Improved WIS", "Not Improved WIS")

# Create the ggplot histogram
ggplot(W4_map, aes(x = percentage_improvement, fill = category)) +
  geom_histogram(binwidth = 5, color = "white", boundary = 0) +  # Set bin width to 5
  scale_fill_manual(values = c("Improved WIS" = "blue", "Not Improved WIS" = "red")) +  # Color mapping
  scale_x_continuous(breaks = seq(-5, 35, by = 5), limits = c(-5, 35)) +  # Set x-axis breaks
  labs(title = "Mean WIS improvement % by each state compared to AUTO ARIMA (Wk4)",
       x = "Improvement % = (WIS AUTO_ARIMA - WIS BEST MODEL) / WIS AUTO_ARIMA)*100",
       y = "Frequency", fill=NULL) +
  theme_minimal()
```


Now let's evaluate which are the best models by each epidemiological week
Here I define some colors and model order for the next plots.

```{r}
# Define a color palette for models
model_colors <- c(
  "AUTO_AR" = "#a6cee3",  # Blue
  "ES27_AR" = "#226e83",  # Light blue
  "ES64_AR" = "#08306b",  # Green
  "AUTO_ADJ" = "#fb9a99", # Red
  "ES27_ADJ" = "red3", # Light red #fb9a99
  "ES64_ADJ" = "#a11c3e", # Orange
  "AUTO_EPI" = "#cab2d6", # Yellow
  "ES27_EPI" = "purple2", # Lavender
  "ES64_EPI" = "#5e2b7b", # Purple
  "AUTO_TEMP" = "lightgreen",# Light orange
  "ES27_TEMP" = "green3", # Light green
  "ES64_TEMP" = "#319045" # Pale yellow
)

# Define the model order
model_order <- c(
  "AUTO_AR", "ES27_AR", "ES64_AR",
  "AUTO_ADJ", "ES27_ADJ", "ES64_ADJ",
  "AUTO_EPI", "ES27_EPI", "ES64_EPI",
  "AUTO_TEMP", "ES27_TEMP", "ES64_TEMP"
)
```

1 week ahead

```{r}
# Reshape the dataframe to long format for easier processing
df_long <- filtered_df_W1 %>%
  pivot_longer(cols = -c(STATE, Julian_date, epiweek),  # Keep Julian_date, epiweek, and STATE 
               names_to = "model", values_to = "WIS") %>%
  mutate(model = gsub("_WIS", "", model))  # Remove _WIS suffix from model names

# Find the best model by Julian_date and STATE
best_model_per_state_date <- df_long %>%
  group_by(STATE, Julian_date) %>%
  slice(which.min(WIS)) %>%
  ungroup()

# Count occurrences of each best model by epiweeks across all states
counts_per_week <- best_model_per_state_date %>%
  group_by(epiweek, model) %>%
  summarize(count = n(), .groups = 'drop')

# Convert 'model' to a factor with custom levels
counts_per_week$model <- factor(counts_per_week$model, levels = model_order)

# Reorder epiweeks to start from week 39 to 53, then 1 to 38
epiweek_levels <- c(40:52, 1:20)

counts_per_week <- counts_per_week %>%
  mutate(epiweek = factor(epiweek, levels = epiweek_levels))

# Calculate total counts for each epiweek
total_counts_per_week <- counts_per_week %>%
  group_by(epiweek) %>%
  summarize(total_count = sum(count), .groups = 'drop')

# Join total counts back to counts_per_week and calculate percentages
counts_per_week <- counts_per_week %>%
  left_join(total_counts_per_week, by = "epiweek") %>%
  mutate(percentage = (count / total_count) * 100)
# Plot the best model counts as percentages
ggplot() +
  geom_bar(data = counts_per_week, aes(x = epiweek, y = percentage, fill = model), 
           stat = "identity", position = "stack", width = 0.7) +
  scale_x_discrete(labels = as.character(epiweek_levels)) +
  labs(x = "Epidemiological weeks", 
       y = "Percentage of Best Models", 
       fill = "Model", 
       title = "Percentage of best models by epidemiological week (1Wk)",  
       subtitle = "Results for 47 U.S. states") +
  scale_fill_manual(values = model_colors) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 80, hjust = 1))

```

2 weeks ahead

```{r}
# Reshape the dataframe to long format for easier processing
df_long <- filtered_df_W2 %>%
  pivot_longer(cols = -c(STATE, Julian_date, epiweek),  # Keep Julian_date, epiweek, and STATE 
               names_to = "model", values_to = "WIS") %>%
  mutate(model = gsub("_WIS", "", model))  # Remove _WIS suffix from model names

# Find the best model by Julian_date and STATE
best_model_per_state_date <- df_long %>%
  group_by(STATE, Julian_date) %>%
  slice(which.min(WIS)) %>%
  ungroup()

# Count occurrences of each best model by epiweeks across all states
counts_per_week <- best_model_per_state_date %>%
  group_by(epiweek, model) %>%
  summarize(count = n(), .groups = 'drop')

# Convert 'model' to a factor with custom levels
counts_per_week$model <- factor(counts_per_week$model, levels = model_order)

# Reorder epiweeks to start from week 39 to 53, then 1 to 38
epiweek_levels <- c(40:52, 1:20)

counts_per_week <- counts_per_week %>%
  mutate(epiweek = factor(epiweek, levels = epiweek_levels))

# Calculate total counts for each epiweek
total_counts_per_week <- counts_per_week %>%
  group_by(epiweek) %>%
  summarize(total_count = sum(count), .groups = 'drop')

# Join total counts back to counts_per_week and calculate percentages
counts_per_week <- counts_per_week %>%
  left_join(total_counts_per_week, by = "epiweek") %>%
  mutate(percentage = (count / total_count) * 100)
# Plot the best model counts as percentages
ggplot() +
  geom_bar(data = counts_per_week, aes(x = epiweek, y = percentage, fill = model), 
           stat = "identity", position = "stack", width = 0.7) +
  scale_x_discrete(labels = as.character(epiweek_levels)) +
  labs(x = "Epidemiological weeks", 
       y = "Percentage of Best Models", 
       fill = "Model", 
       title = "Percentage of best models by epidemiological week (2Wk)",  
       subtitle = "Results for 47 U.S. states") +
  scale_fill_manual(values = model_colors) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 80, hjust = 1))

```

3 weeks ahead

```{r}
# Reshape the dataframe to long format for easier processing
df_long <- filtered_df_W3 %>%
  pivot_longer(cols = -c(STATE, Julian_date, epiweek),  # Keep Julian_date, epiweek, and STATE 
               names_to = "model", values_to = "WIS") %>%
  mutate(model = gsub("_WIS", "", model))  # Remove _WIS suffix from model names

# Find the best model by Julian_date and STATE
best_model_per_state_date <- df_long %>%
  group_by(STATE, Julian_date) %>%
  slice(which.min(WIS)) %>%
  ungroup()

# Count occurrences of each best model by epiweeks across all states
counts_per_week <- best_model_per_state_date %>%
  group_by(epiweek, model) %>%
  summarize(count = n(), .groups = 'drop')

# Convert 'model' to a factor with custom levels
counts_per_week$model <- factor(counts_per_week$model, levels = model_order)

# Reorder epiweeks to start from week 39 to 53, then 1 to 38
epiweek_levels <- c(40:52, 1:20)

counts_per_week <- counts_per_week %>%
  mutate(epiweek = factor(epiweek, levels = epiweek_levels))

# Calculate total counts for each epiweek
total_counts_per_week <- counts_per_week %>%
  group_by(epiweek) %>%
  summarize(total_count = sum(count), .groups = 'drop')

# Join total counts back to counts_per_week and calculate percentages
counts_per_week <- counts_per_week %>%
  left_join(total_counts_per_week, by = "epiweek") %>%
  mutate(percentage = (count / total_count) * 100)
# Plot the best model counts as percentages
ggplot() +
  geom_bar(data = counts_per_week, aes(x = epiweek, y = percentage, fill = model), 
           stat = "identity", position = "stack", width = 0.7) +
  scale_x_discrete(labels = as.character(epiweek_levels)) +
  labs(x = "Epidemiological weeks", 
       y = "Percentage of Best Models", 
       fill = "Model", 
       title = "Percentage of best models by epidemiological week (3Wk)",  
       subtitle = "Results for 47 U.S. states") +
  scale_fill_manual(values = model_colors) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 80, hjust = 1))

```

4 weeks ahead

```{r}
# Reshape the dataframe to long format for easier processing
df_long <- filtered_df_W4 %>%
  pivot_longer(cols = -c(STATE, Julian_date, epiweek),  # Keep Julian_date, epiweek, and STATE 
               names_to = "model", values_to = "WIS") %>%
  mutate(model = gsub("_WIS", "", model))  # Remove _WIS suffix from model names

# Find the best model by Julian_date and STATE
best_model_per_state_date <- df_long %>%
  group_by(STATE, Julian_date) %>%
  slice(which.min(WIS)) %>%
  ungroup()

# Count occurrences of each best model by epiweeks across all states
counts_per_week <- best_model_per_state_date %>%
  group_by(epiweek, model) %>%
  summarize(count = n(), .groups = 'drop')

# Convert 'model' to a factor with custom levels
counts_per_week$model <- factor(counts_per_week$model, levels = model_order)

# Reorder epiweeks to start from week 39 to 53, then 1 to 38
epiweek_levels <- c(40:52, 1:20)

counts_per_week <- counts_per_week %>%
  mutate(epiweek = factor(epiweek, levels = epiweek_levels))

# Calculate total counts for each epiweek
total_counts_per_week <- counts_per_week %>%
  group_by(epiweek) %>%
  summarize(total_count = sum(count), .groups = 'drop')

# Join total counts back to counts_per_week and calculate percentages
counts_per_week <- counts_per_week %>%
  left_join(total_counts_per_week, by = "epiweek") %>%
  mutate(percentage = (count / total_count) * 100)
# Plot the best model counts as percentages
ggplot() +
  geom_bar(data = counts_per_week, aes(x = epiweek, y = percentage, fill = model), 
           stat = "identity", position = "stack", width = 0.7) +
  scale_x_discrete(labels = as.character(epiweek_levels)) +
  labs(x = "Epidemiological weeks", 
       y = "Percentage of Best Models", 
       fill = "Model", 
       title = "Percentage of best models by epidemiological week (4Wk)",  
       subtitle = "Results for 47 U.S. states") +
  scale_fill_manual(values = model_colors) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 80, hjust = 1))

```

Loading datasets for regression analysis

```{r}
pop_data <- read.csv("regression_features/population_data.csv") # resident population and population density
sovi_data <- read.csv("regression_features/sovi_2010.2014.csv") # SOVI index
bric_data<-read.csv("regression_features/bric2015.csv") # BRIC index
humidity_data<-read.csv("regression_features/humidity_climatology_1990_2020.csv") # ERA5 Specific Humidity
temperature_data<-read.csv("regression_features/temperature_climatology_1990_2020.csv") # ERA5 Specific Temperature

```

REGRESSION MODELS

We will run the regression for evaluating if the best model log(WIS) which represent its performance is related to given independent variables.

```{r}

# List of data frames
WIS_dataframes <- list(W1 = W1, W2 = W2, W3 = W3, W4=W4)
regression_models<-data.frame()

```

All Regression results

AUTO_ADJ WIS x RESIDENT POPULATION 2020

```{r}

for(i in c(1,2,3,4)){

  # Combining data for the same states
  colnames(WIS_dataframes[[i]])[1] <- "STATE"
  WIS_dataframes[[i]]$STATE <- as.character(WIS_dataframes[[i]]$STATE)
  WIS_pop_data <- inner_join(WIS_dataframes[[i]], pop_data, by = "STATE")
  # Fitting the regression model
  model <- lm(log1p(WIS_pop_data$AUTO_ADJ) ~ log(WIS_pop_data$Resident_population_2020))
  # View the model summary
  model_summary <- summary(model)
  # Getting the R and p values for the plot
  r_squared <- round(model_summary$r.squared, 3)
  p_value <- signif(model_summary$coefficients[2, 4], 3)
  # Saving the results in a dataframe
  regression_models2 <- data.frame(
    independent_variable = "Resident Population (2020)", 
    Week_Ahead = i, 
    r_squared = r_squared, 
    p_value = p_value
  )
  # Append to the main results dataframe
  regression_models <- rbind(regression_models, regression_models2)
}

```

AUTO_ADJ WIS x POPULATION DENSITY

```{r}

for(i in c(1,2,3,4)){

  WIS_pop_data <- inner_join(WIS_dataframes[[i]], pop_data, by = "STATE")
  # Fit the regression model
  model <- lm(log1p(WIS_pop_data$AUTO_ADJ) ~ log(WIS_pop_data$Population_density_2020))
  # View the model summary
  model_summary <- summary(model)
  # Extract R-squared and p-value
  r_squared <- round(model_summary$r.squared, 3)
  p_value <- signif(model_summary$coefficients[2, 4], 3)
  # saving the results in a dataframe
  regression_models2<-data.frame("independent_variable"="Population Density (2020)","Week_Ahead"=i, "r_squared"=r_squared,"p_value"= p_value)
  # Append to the main results dataframe
  regression_models<-rbind(regression_models,regression_models2)
}

```

Here we will weight the Social Vulnerability Index (SoVI) and Baseline Resilience Indicators for Communities (BRIC) county indexes which for each states based on the population size in each county.

```{r}
#############################################################
# SOVI BY STATE
# weighted by population size in each county
sovi_by_state <- sovi_data %>%
  filter(!is.nan(sovi)) %>%  # Exclude rows where 'sovi' is NaN
  group_by(state.name) %>%
  summarize(weighted_mean = weighted.mean(sovi, w = population.2020, na.rm = TRUE))

colnames(sovi_by_state)[1] <- "STATE"

#############################################################
# BRIC BY STATE
# weighted by population size in each county

bric_by_state <- bric_data %>%
  group_by(state.name) %>%
  summarize(across(16:22, ~ weighted.mean(.x, w = population.2020, na.rm = TRUE), .names = "weighted_mean_{col}"))
colnames(bric_by_state)[1] <- "STATE"

```

AUTO_ADJ WIS x SOVI

```{r}

for(i in c(1,2,3,4)){

  WIS_sovi<-NULL
  WIS_sovi <- inner_join(WIS_dataframes[[i]], sovi_by_state, by = "STATE")
  # Fit the regression model
  model <- lm(log(WIS_sovi$AUTO_ADJ) ~ (WIS_sovi$weighted_mean))
  # View the model summary
  model_summary <- summary(model)
  # Extract R-squared and p-value
  r_squared <- round(model_summary$r.squared, 3)
  p_value <- signif(model_summary$coefficients[2, 4], 3)
  # saving the results in a dataframe
  regression_models2<-data.frame("independent_variable"="Social Vulnerability Index (SoVI)","Week_Ahead"=i, "r_squared"=r_squared,"p_value"= p_value)
  # appending the results
  regression_models<-rbind(regression_models,regression_models2)
}

```

AUTO_ADJ WIS x BRIC SOCIAL

```{r}

for(i in 1:4){
  WIS_bric <- inner_join(WIS_dataframes[[i]], bric_by_state, by = "STATE")
  # Fit the regression model  
  model <- lm(log(WIS_bric$AUTO_ADJ) ~ (WIS_bric$weighted_mean_z_bric.social))
  # View the model summary
  model_summary <- summary(model)
  # Extract R-squared and p-value
  r_squared <- round(model_summary$r.squared, 3)
  p_value <- signif(model_summary$coefficients[2, 4], 3)
  # saving the results in a dataframe
  regression_models2<-data.frame("independent_variable"="BRIC Social (2015)","Week_Ahead"=i, "r_squared"=r_squared,"p_value"= p_value)
  # appending the results
  regression_models<-rbind(regression_models,regression_models2)
}

```

AUTO_ADJ WIS x BRIC ECONOMIC

```{r}
for(i in 1:4){
  WIS_bric <- inner_join(WIS_dataframes[[i]], bric_by_state, by = "STATE")
  # Fit the regression model
  model <- lm(log(WIS_bric$AUTO_ADJ) ~ (WIS_bric$weighted_mean_z_bric.economic))
  # View the model summary
  model_summary <- summary(model)
  # Extract R-squared and p-value
  r_squared <- round(model_summary$r.squared, 3)
  p_value <- signif(model_summary$coefficients[2, 4], 3)
  # saving the results in a dataframe
  regression_models2<-data.frame("independent_variable"="BRIC Economic (2015)","Week_Ahead"=i, "r_squared"=r_squared,"p_value"= p_value)
  regression_models<-rbind(regression_models,regression_models2)
}

```

AUTO_ADJ WIS x BRIC Infrastructure

```{r}

for (i in 1:4){
  WIS_bric <- inner_join(WIS_dataframes[[i]], bric_by_state, by = "STATE")
  # Fit the regression model
  model <- lm(log(WIS_bric$AUTO_ADJ) ~ (WIS_bric$weighted_mean_z_bric.infrastructure))
  # View the model summary
  model_summary <- summary(model)
  # Extract R-squared and p-value
  r_squared <- round(model_summary$r.squared, 3)
  p_value <- signif(model_summary$coefficients[2, 4], 3)
  # saving the results in a dataframe
  regression_models2<-data.frame("independent_variable"="BRIC Infrastructure (2015)","Week_Ahead"=i, "r_squared"=r_squared,"p_value"= p_value)
  # appending results
  regression_models<-rbind(regression_models,regression_models2)
}

```
AUTO_ADJ WIS x BRIC institutional

```{r}

for (i in 1:4){
  WIS_bric <- inner_join(WIS_dataframes[[i]], bric_by_state, by = "STATE")
  # Fit the regression model
  model <- lm(log(WIS_bric$AUTO_ADJ) ~ (WIS_bric$weighted_mean_z_bric.institutional))
  # View the model summary
  model_summary <- summary(model)
  # Extract R-squared and p-value
  r_squared <- round(model_summary$r.squared, 3)
  p_value <- signif(model_summary$coefficients[2, 4], 3)
  # saving the results in a dataframe
  regression_models2<-data.frame("independent_variable"="BRIC Institutional (2015)","Week_Ahead"=i, "r_squared"=r_squared,"p_value"= p_value)
  # appending results
  regression_models<-rbind(regression_models,regression_models2)
}

```

AUTO_ADJ WIS x BRIC community

```{r}

for(i in 1:4){
  WIS_bric <- inner_join(WIS_dataframes[[1]], bric_by_state, by = "STATE")
  # Fit the regression model
  model <- lm(log(WIS_bric$AUTO_ADJ) ~ (WIS_bric$weighted_mean_z_bric.community))
  # View the model summary
  model_summary <- summary(model)
  # Extract R-squared and p-value
  r_squared <- round(model_summary$r.squared, 3)
  p_value <- signif(model_summary$coefficients[2, 4], 3)
  # saving the results in a dataframe
  regression_models2<-data.frame("independent_variable"="BRIC Community (2015)","Week_Ahead"=i, "r_squared"=r_squared,"p_value"= p_value)
  regression_models<-rbind(regression_models,regression_models2)
}

```

AUTO_ADJ WIS x BRIC environment

```{r}

for(i in 1:4){
  WIS_bric <- inner_join(WIS_dataframes[[i]], bric_by_state, by = "STATE")
  # Fit the regression model
  model <- lm(log(WIS_bric$AUTO_ADJ) ~ (WIS_bric$weighted_mean_z_bric.environment))
  # View the model summary
  model_summary <- summary(model)
  # Extract R-squared and p-value
  r_squared <- round(model_summary$r.squared, 3)
  p_value <- signif(model_summary$coefficients[2, 4], 3)
  # saving the results in a dataframe
  regression_models2<-data.frame("independent_variable"="BRIC Environment (2015)","Week_Ahead"=i, "r_squared"=r_squared,"p_value"= p_value)
  regression_models<-rbind(regression_models,regression_models2)
}

```
AUTO_ADJ WIS x BRIC total

```{r}

for(i in 1:4){
  # BRIC INDEX
  WIS_bric <- inner_join(WIS_dataframes[[i]], bric_by_state, by = "STATE")
  # Fit the regression model
  model <- lm(log(WIS_bric$AUTO_ADJ) ~ (WIS_bric$weighted_mean_z_bric.total))
  # View the model summary
  model_summary <- summary(model)
  # Extract R-squared and p-value
  r_squared <- round(model_summary$r.squared, 3)
  p_value <- signif(model_summary$coefficients[2, 4], 3)
  # saving the results in a dataframe
  regression_models2<-data.frame("independent_variable"="BRIC total (2015)","Week_Ahead"=i, "r_squared"=r_squared,"p_value"= p_value)
  regression_models<-rbind(regression_models,regression_models2)
}
```

TEMPERATUE - ERA5

Now we will look at regression models that uses mean temperature and specific humidity.

-------------------

AUTO_ADJ WIS x Temperature ERA5 Data

```{r}
for(i in 1:4){
  # TEMPERATURE DATA from ERA5
  WIS_temp <- inner_join(WIS_dataframes[[i]], temperature_data, by = "STATE")
  # Fit the regression model
  model <- lm(log(WIS_temp$AUTO_ADJ) ~ (WIS_temp$mean))
  # View the model summary
  model_summary <- summary(model)
  # Extract R-squared and p-value
  r_squared <- round(model_summary$r.squared, 3)
  p_value <- signif(model_summary$coefficients[2, 4], 3)
  # saving the results in a dataframe
  regression_models2<-data.frame("independent_variable"="Mean Temperature (1990-2020)","Week_Ahead"=i, "r_squared"=r_squared,"p_value"= p_value)
  # appending results
  regression_models<-rbind(regression_models,regression_models2)
}
```

AUTO_ADJ WIS x Specific Humidity ERA5 Data

```{r}
# regression results 
print(regression_models)

for(i in 1:4){
  # HUMIDITY DATA from ERA5
  WIS_humidity <- inner_join(WIS_dataframes[[i]], humidity_data, by = "STATE")
  # Fit the regression model
  model <- lm(log(WIS_humidity$AUTO_ADJ) ~ (WIS_humidity$mean))
  # View the model summary
  model_summary <- summary(model)
  # Extract R-squared and p-value
  r_squared <- round(model_summary$r.squared, 3)
  p_value <- signif(model_summary$coefficients[2, 4], 3)
  # saving the results in a dataframe
  regression_models2<-data.frame("independent_variable"="Mean Specific Humidty (1990-2020)","Week_Ahead"=i, "r_squared"=r_squared,"p_value"= p_value)
  # appending results
  regression_models<-rbind(regression_models,regression_models2)
}
```

SUMMARY OF RESULTS 

```{r}
# Add a significance indicator for coloring
data <- regression_models %>%
  mutate(Significant = ifelse(p_value < 0.05, "Significant", "Not Significant"))

# Plot R-squared with conditional coloring and faceting by Week_Ahead
ggplot(data, aes(x = independent_variable, y = r_squared, fill = Significant)) +
  geom_col(color = "black", width = 0.5) +
  scale_fill_manual(values = c("Significant" = "blue", "Not Significant" = "red")) +
  labs(
    title = "Regression Models of the AUTO_ADJ performance (on log(WIS)) for 48 U.S. States (1 to 4 weeks ahead)",
    subtitle = "Blue bars indicate p-values < 0.05",
    x = "Independent Variables",
    y = "R-squared",
    fill = "Significance"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_wrap(~Week_Ahead, ncol = 1)

# Save the plot with specified size
#ggsave("regression_plot.jpg", width = 10, height = 14, dpi = 300)
```

######################
Friedman variance test
######################

1 WEEK AHEAD Post Hoc Wilcox test

```{r}
library(lme4)
library(ez)

# Reshape the data into long format
long_data <- W1 %>%
  pivot_longer(cols = c(-STATE,-Best_Result) , names_to = "Type", values_to = "Value")%>%
  mutate(Type = recode(Type, "AUTO_AR" = "AUTO_AAR"))

######################
# Friedman test since we have related samples (models by each STATE)
# and non-normally distributed data
# therefore, it could be better to use this non-parametric test

week1_wis_test<-friedman.test(Value ~ Type | STATE, data = long_data)
# results
friedman_results_w1<-data.frame("chi_squared"=week1_wis_test$statistic, "p_value"=week1_wis_test$p.value)
#friedman_results_w1

#########################################################################
wilcox_results <- pairwise.wilcox.test(long_data$Value, long_data$Type, 
                                       p.adjust.method ="BY", 
                                       paired = TRUE)
p_values<-wilcox_results$p.value 
p_values<-data.frame(p_values)

#########################################################################
p_df1 <- data.frame(Models = rownames(p_values), PValue = p_values$AUTO_AAR, WeekAhead=1)
p_df1 <-drop_na(p_df1)
#p_df1

```

2 WEEKS AHEAD Post Hoc Wilcox test

```{r}
# Reshape the data into long format
long_data <- W2 %>%
  pivot_longer(cols = c(-STATE,-Best_Result) , names_to = "Type", values_to = "Value")%>%
  mutate(Type = recode(Type, "AUTO_AR" = "AUTO_AAR"))

######################
# Friedman test since we have related samples (models by each STATE)
# and non-normally distributed data
# therefore, it could be better to use this non-parametric test
week2_wis_test<-friedman.test(Value ~ Type | STATE, data = long_data)
# adding results to the dataframe
friedman_results_w2<-data.frame("chi_squared"=week2_wis_test$statistic, "p_value"=week2_wis_test$p.value)

#########################################################################
wilcox_results <- pairwise.wilcox.test(long_data$Value, long_data$Type, 
                                       p.adjust.method ="BY"  , 
                                       paired = TRUE)

p_values<-wilcox_results$p.value 
p_values<-data.frame(p_values)

#########################################################################
p_df2 <- data.frame(Models = rownames(p_values), PValue = p_values$AUTO_AAR, WeekAhead=2)
p_df2 <-drop_na(p_df2)
#p_df2

```

3 WEEKS AHEAD Post Hoc Wilcox test

```{r}
# Reshape the data into long format
long_data <- W3 %>%
  pivot_longer(cols = c(-STATE,-Best_Result) , names_to = "Type", values_to = "Value")%>%
  mutate(Type = recode(Type, "AUTO_AR" = "AUTO_AAR"))

######################
# Friedman test since we have related samples (models by each STATE)
# and non-normally distributed data
# therefore, it could be better to use this non-parametric test
week3_wis_test<-friedman.test(Value ~ Type | STATE, data = long_data)
# adding results to the dataframe
friedman_results_w3<-data.frame("chi_squared"=week3_wis_test$statistic, "p_value"=week3_wis_test$p.value)

#########################################################################
wilcox_results <- pairwise.wilcox.test(long_data$Value, long_data$Type, 
                                       p.adjust.method ="BY"  , 
                                       paired = TRUE)

p_values<-wilcox_results$p.value 
p_values<-data.frame(p_values)

#########################################################################
p_df3 <- data.frame(Models = rownames(p_values), PValue = p_values$AUTO_AAR, WeekAhead=3)
p_df3 <-drop_na(p_df3)
#p_df3
```

4 WEEKS AHEAD Post Hoc Wilcox test

```{r}
# Reshape the data into long format
long_data <- W4 %>%
  pivot_longer(cols = c(-STATE,-Best_Result) , names_to = "Type", values_to = "Value")%>%
  mutate(Type = recode(Type, "AUTO_AR" = "AUTO_AAR"))

######################
# Friedman test since we have related samples (models by each STATE)
# and non-normally distributed data
# therefore, it could be better to use this non-parametric test
week4_wis_test<-friedman.test(Value ~ Type | STATE, data = long_data)
# adding results to the dataframe
friedman_results_w4<-data.frame("chi_squared"=week4_wis_test$statistic, "p_value"=week4_wis_test$p.value)

#########################################################################
wilcox_results <- pairwise.wilcox.test(long_data$Value, long_data$Type, 
                                       p.adjust.method ="BY"  , 
                                       paired = TRUE)

p_values<-wilcox_results$p.value 
p_values<-data.frame(p_values)

#########################################################################
p_df4 <- data.frame(Models = rownames(p_values), PValue = p_values$AUTO_AAR, WeekAhead=4)
p_df4 <-drop_na(p_df4)
#p_df4

```

Friedman test 

```{r}
friedman_results<-rbind("1week_ahead"=friedman_results_w1,"2week_ahead"=friedman_results_w2,"3week_ahead"=friedman_results_w3,"4week_ahead"=friedman_results_w4)

weeks_<-data.frame("weeks_ahead"=c(1,2,3,4))

friedman_results<-cbind(friedman_results,weeks_)

# Define significance threshold (e.g., 0.05)
significance_level <- 0.05

# Add a new column to classify significance
friedman_results$significance <- ifelse(friedman_results$p_value < significance_level, "Significant", "Not Significant")

# Create the barplot
ggplot(friedman_results, aes(x = factor(weeks_ahead), y = 1, fill = significance)) +
  geom_tile(color = "black") +  # Add black borders to squares
  scale_fill_manual(values = c("Significant" = "blue", "Not Significant" = "red")) +
  labs(title = "Significance of Friedman tests for models' results according to each state",
       x = "Week Ahead",
       y = "Results",
       fill = "Significance") + 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.text.y = element_blank(),   # Remove y-axis values
        axis.ticks.y = element_blank())

```

Summary of Post Hoc Wilcox test with  p.adjust.method Benjamini-Yekutieli (BY)

```{r}

all_p_values<-rbind(p_df1,p_df2,p_df3,p_df4)
all_p_values

# Define significance threshold
alpha <- 0.05  

# Create significance column
p_df <- all_p_values %>%
  mutate(Significance = ifelse(PValue < alpha, "Significant", "Not Significant"))

# Plot
ggplot(p_df, aes(x = factor(WeekAhead), y = Models, fill = Significance)) +
  geom_tile(color = "black") +  # Add black borders to squares
  scale_fill_manual(values = c("Significant" = "blue", "Not Significant" = "red")) +
  labs(title = "Post Hoc comparisons with AUTO_AR - Wilcox test with BY adjustment",
       subtitle = "Significant for p_value < 0.05",
       x = "Week Ahead",
       y = "Models",
       fill = "") + 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 

```

This figure is just a example of a probabilistic forecast for 4 weeks ahead.

```{r}
# Load necessary library
library(ggplot2)

# Example data
data <- data.frame(
  horizon = c(1, 2, 3, 4),
  mean = c(10, 20, 30, 40),
  lower = c(5, 9, 15, 20),
  upper = c(15, 28, 40, 60)
)

# Create the plot
ggplot(data, aes(x = horizon, y = mean)) +
  geom_line(color = 'blue', size = 4) +           # Line for the forecast mean
  geom_point(color = 'red', size = 8) +           # Points for the forecast mean
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) +  # Confidence interval ribbon
  labs(
    x = 'Forecast Horizon',
    y = 'Forecast Value',
    title = 'Probabilistic Forecast with 99% Confidence Interval'
  ) +
  theme_minimal() +                     # Clean theme
  theme(
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    plot.title = element_text(size = 14, face = 'bold'),
    legend.text = element_text(size = 12),  # Increase legend text size
    legend.title = element_text(size = 12)  # Increase legend title size
  )
```